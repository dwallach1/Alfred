
# coding: utf-8

# In[ ]:


get_ipython().system('pip install gensim')
get_ipython().system('pip install fuzzywuzzy')
get_ipython().system('pip install tqdm')
get_ipython().system('pip install gcsfs')
get_ipython().system('pip install python-Levenshtein')
get_ipython().system('pip install pyemd')


import pandas as pd
import numpy as np

import pickle
import pandas as pd
import numpy as np
import gensim
from fuzzywuzzy import fuzz
from nltk.corpus import stopwords
from tqdm import tqdm
from scipy.stats import skew, kurtosis
from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis
from nltk import word_tokenize
stop_words = stopwords.words('english')
import nltk
import gcsfs
import jonahs_things as ja
from pyemd import emd
from gensim.similarities import WmdSimilarity
import gzip
#nltk.download()


# In[1]:


#Pickling Supplies
# base dir "/jaa-bucket2/"
#gcs_pickle(data, "/jaa-bucket2/Quora_featured")
#gcs_unpickle("/jaa-bucket2/Quora_featured")
get_ipython().system('pip install gcsfs')
import gcsfs
def gcs_pickle(self,directory):
  fs = gcsfs.GCSFileSystem()
  with fs.open(directory, 'wb') as f:
      pickle.dump(self, f)
def gcs_unpickle(directory):
  fs = gcsfs.GCSFileSystem()
  with fs.open(directory, 'rb') as f:
      element = pickle.load(f)
  return element


# In[ ]:


this_location ="/jaa-bucket2/"
df=ja.get_file(this_location,'train')


# In[ ]:


data = df
data = data.drop(['id', 'qid1', 'qid2'], axis=1)


# In[ ]:


def get_file_general(location,file_name):
    fs = gcsfs.GCSFileSystem(project='adlerj')
    with fs.open(location+file_name) as f:
        return f


def wmd(s1, s2):
    s1 = str(s1).lower().split()
    s2 = str(s2).lower().split()
    stop_words = stopwords.words('english')
    s1 = [w for w in s1 if w not in stop_words]
    s2 = [w for w in s2 if w not in stop_words]
    return model.wmdistance(s1, s2)


def norm_wmd(s1, s2):
    s1 = str(s1).lower().split()
    s2 = str(s2).lower().split()
    stop_words = stopwords.words('english')
    s1 = [w for w in s1 if w not in stop_words]
    s2 = [w for w in s2 if w not in stop_words]
    return norm_model.wmdistance(s1, s2)


def sent2vec(s):
    words = str(s).lower()
    words = word_tokenize(words)
    words = [w for w in words if not w in stop_words]
    words = [w for w in words if w.isalpha()]
    M = []
    for w in words:
        try:
            M.append(model[w])
        except:
            continue
    M = np.array(M)
    v = M.sum(axis=0)
    return v / np.sqrt((v ** 2).sum())


# In[ ]:



print ('creating first set of features')
data['len_q1'] = data.question1.apply(lambda x: len(str(x)))
data['len_q2'] = data.question2.apply(lambda x: len(str(x)))
data['diff_len'] = data.len_q1 - data.len_q2
data['len_char_q1'] = data.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))
data['len_char_q2'] = data.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))
data['len_word_q1'] = data.question1.apply(lambda x: len(str(x).split()))
data['len_word_q2'] = data.question2.apply(lambda x: len(str(x).split()))
data['common_words'] = data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)


data['fuzz_qratio'] = data.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_WRatio'] = data.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_partial_ratio'] = data.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_partial_token_set_ratio'] = data.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_token_set_ratio'] = data.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)
data['fuzz_token_sort_ratio'] = data.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)


# In[ ]:


data.to_csv("data_pt1")


# In[81]:


data = pd.read_csv("data_pt1")
data = data.drop(data.columns[0], axis=1)


# In[74]:


#sample for quickness
#data = data.iloc[0:20,:].copy()


# In[82]:


question1_vectors = np.zeros((data.shape[0], 300))
error_count = 0


# In[ ]:


location,file_name= ("/jaa-bucket2/",'GoogleNews-vectors-negative300.bin.gz')
fs = gcsfs.GCSFileSystem(project='adlerj')
model=0
with fs.open(location+file_name) as f:
  f2 = gzip.GzipFile(fileobj=f)
  model=gensim.models.KeyedVectors.load_word2vec_format(f2, binary=True)

norm_model = model


# In[83]:


data['wmd'] = data.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)
norm_model.init_sims(replace=True)
data['norm_wmd'] = data.apply(lambda x: norm_wmd(x['question1'], x['question2']), axis=1)


# In[84]:



question1_vectors = np.zeros((data.shape[0], 300))
error_count = 0

for i, q in tqdm(enumerate(data.question1.values)):
    question1_vectors[i, :] = sent2vec(q)

question2_vectors  = np.zeros((data.shape[0], 300))
for i, q in tqdm(enumerate(data.question2.values)):
    question2_vectors[i, :] = sent2vec(q)


# In[85]:




data['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors),
                                                          np.nan_to_num(question2_vectors))]

data['skew_q1vec'] = [skew(x) for x in np.nan_to_num(question1_vectors)]
data['skew_q2vec'] = [skew(x) for x in np.nan_to_num(question2_vectors)]
data['kur_q1vec'] = [kurtosis(x) for x in np.nan_to_num(question1_vectors)]
data['kur_q2vec'] = [kurtosis(x) for x in np.nan_to_num(question2_vectors)]


# In[112]:


q1v = pd.DataFrame(question1_vectors)
q2v = pd.DataFrame(question2_vectors)


# In[113]:


data = pd.concat([data, q1v,q2v], axis=1)


# In[114]:


data.to_pickle("Quora_featured")


# In[111]:


#data = data.iloc[0:-1,:-600].copy()

